"use strict";(globalThis.webpackChunkros2_book=globalThis.webpackChunkros2_book||[]).push([[392],{5292(n,e,i){i.r(e),i.d(e,{assets:()=>l,contentTitle:()=>r,default:()=>m,frontMatter:()=>s,metadata:()=>a,toc:()=>d});const a=JSON.parse('{"id":"module2/sensor-simulation","title":"Sensor Simulation","description":"Learning Objectives","source":"@site/docs/module2/sensor-simulation.md","sourceDirName":"module2","slug":"/module2/sensor-simulation","permalink":"/docs/module2/sensor-simulation","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/module2/sensor-simulation.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3},"sidebar":"tutorialSidebar","previous":{"title":"Gazebo Physics Simulation","permalink":"/docs/module2/gazebo-physics-simulation"},"next":{"title":"Unity High-Fidelity Rendering & Human-Robot Interaction","permalink":"/docs/module2/unity-rendering-hri"}}');var o=i(4848),t=i(8453);const s={sidebar_position:3},r="Sensor Simulation",l={},d=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Prerequisites",id:"prerequisites",level:2},{value:"Introduction to Sensor Simulation",id:"introduction-to-sensor-simulation",level:2},{value:"Key Sensor Types for Robotics:",id:"key-sensor-types-for-robotics",level:3},{value:"LiDAR Sensor Simulation",id:"lidar-sensor-simulation",level:2},{value:"LiDAR Principles",id:"lidar-principles",level:3},{value:"Gazebo LiDAR Configuration",id:"gazebo-lidar-configuration",level:3},{value:"2D LiDAR Configuration",id:"2d-lidar-configuration",level:3},{value:"Depth Camera Simulation",id:"depth-camera-simulation",level:2},{value:"Depth Camera Principles",id:"depth-camera-principles",level:3},{value:"Gazebo Depth Camera Configuration",id:"gazebo-depth-camera-configuration",level:3},{value:"IMU Sensor Simulation",id:"imu-sensor-simulation",level:2},{value:"IMU Principles",id:"imu-principles",level:3},{value:"Gazebo IMU Configuration",id:"gazebo-imu-configuration",level:3},{value:"Unity Sensor Visualization",id:"unity-sensor-visualization",level:2},{value:"Point Cloud Visualization in Unity",id:"point-cloud-visualization-in-unity",level:3},{value:"Sensor Data Processing in Unity",id:"sensor-data-processing-in-unity",level:3},{value:"Sensor Integration Examples",id:"sensor-integration-examples",level:2},{value:"Multi-Sensor Fusion World",id:"multi-sensor-fusion-world",level:3},{value:"Exercises",id:"exercises",level:2},{value:"Exercise 1: Configure a LiDAR Sensor and Visualize Its Point Cloud Data",id:"exercise-1-configure-a-lidar-sensor-and-visualize-its-point-cloud-data",level:3},{value:"Exercise 2: Simulate Depth Camera Data for a Simple Scene",id:"exercise-2-simulate-depth-camera-data-for-a-simple-scene",level:3},{value:"Summary",id:"summary",level:2}];function c(n){const e={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.R)(),...n.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(e.header,{children:(0,o.jsx)(e.h1,{id:"sensor-simulation",children:"Sensor Simulation"})}),"\n",(0,o.jsx)(e.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,o.jsx)(e.p,{children:"By the end of this chapter, you will be able to:"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Understand the principles of sensor simulation in Gazebo and Unity"}),"\n",(0,o.jsx)(e.li,{children:"Configure LiDAR sensors for point cloud generation"}),"\n",(0,o.jsx)(e.li,{children:"Set up depth camera simulation for 3D vision"}),"\n",(0,o.jsx)(e.li,{children:"Implement IMU simulation for inertial measurements"}),"\n",(0,o.jsx)(e.li,{children:"Integrate sensor data visualization across both platforms"}),"\n",(0,o.jsx)(e.li,{children:"Create realistic sensor data outputs for robotics applications"}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,o.jsx)(e.p,{children:"Before starting this chapter, you should have:"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Completed the Gazebo Physics Simulation chapter"}),"\n",(0,o.jsx)(e.li,{children:"Completed the Unity Rendering & HRI chapter"}),"\n",(0,o.jsx)(e.li,{children:"Basic understanding of sensor types and their applications in robotics"}),"\n",(0,o.jsx)(e.li,{children:"Knowledge of coordinate systems and transforms"}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"introduction-to-sensor-simulation",children:"Introduction to Sensor Simulation"}),"\n",(0,o.jsx)(e.p,{children:"Sensor simulation is a critical component of robotics development, enabling:"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Perception algorithm testing without physical hardware"}),"\n",(0,o.jsx)(e.li,{children:"Safe evaluation of robot behavior in complex environments"}),"\n",(0,o.jsx)(e.li,{children:"Cost-effective development and debugging"}),"\n",(0,o.jsx)(e.li,{children:"Repeatable experimental conditions"}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"key-sensor-types-for-robotics",children:"Key Sensor Types for Robotics:"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"LiDAR"}),": Light Detection and Ranging for 3D mapping and navigation"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Depth Cameras"}),": RGB-D sensors for 3D scene understanding"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"IMU"}),": Inertial Measurement Units for orientation and motion tracking"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Cameras"}),": Visual sensors for image-based perception"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"GPS"}),": Global positioning for outdoor navigation"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Encoders"}),": Wheel encoders for odometry estimation"]}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"lidar-sensor-simulation",children:"LiDAR Sensor Simulation"}),"\n",(0,o.jsx)(e.h3,{id:"lidar-principles",children:"LiDAR Principles"}),"\n",(0,o.jsx)(e.p,{children:"LiDAR sensors emit laser beams and measure the time it takes for reflections to return, creating accurate 3D point clouds of the environment. In simulation, this is achieved by casting rays and calculating distances to surfaces."}),"\n",(0,o.jsx)(e.h3,{id:"gazebo-lidar-configuration",children:"Gazebo LiDAR Configuration"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-xml",children:'<?xml version="1.0"?>\n<sdf version="1.7">\n  <model name="lidar_sensor">\n    <link name="lidar_link">\n      <pose>0 0 0.1 0 0 0</pose>\n      <inertial>\n        <mass>0.1</mass>\n        <inertia>\n          <ixx>0.0001</ixx>\n          <ixy>0</ixy>\n          <ixz>0</ixz>\n          <iyy>0.0001</iyy>\n          <iyz>0</iyz>\n          <izz>0.0001</izz>\n        </inertia>\n      </inertial>\n\n      <sensor name="lidar_3d" type="ray">\n        <pose>0 0 0 0 0 0</pose>\n        <ray>\n          <scan>\n            <horizontal>\n              <samples>640</samples>\n              <resolution>1</resolution>\n              <min_angle>-1.570796</min_angle>  \x3c!-- -90 degrees --\x3e\n              <max_angle>1.570796</max_angle>   \x3c!-- 90 degrees --\x3e\n            </horizontal>\n            <vertical>\n              <samples>16</samples>\n              <resolution>1</resolution>\n              <min_angle>-0.261799</min_angle>  \x3c!-- -15 degrees --\x3e\n              <max_angle>0.261799</max_angle>   \x3c!-- 15 degrees --\x3e\n            </vertical>\n          </scan>\n          <range>\n            <min>0.1</min>\n            <max>30.0</max>\n            <resolution>0.01</resolution>\n          </range>\n        </ray>\n        <plugin name="lidar_3d_controller" filename="libRayPlugin.so">\n          <always_on>true</always_on>\n          <update_rate>10</update_rate>\n          <topic_name>/lidar_3d_scan</topic_name>\n        </plugin>\n      </sensor>\n\n      <visual name="lidar_visual">\n        <geometry>\n          <cylinder>\n            <radius>0.05</radius>\n            <length>0.05</length>\n          </cylinder>\n        </geometry>\n        <material>\n          <ambient>0.5 0.5 0.5 1</ambient>\n          <diffuse>0.5 0.5 0.5 1</diffuse>\n        </material>\n      </visual>\n\n      <collision name="lidar_collision">\n        <geometry>\n          <cylinder>\n            <radius>0.05</radius>\n            <length>0.05</length>\n          </cylinder>\n        </geometry>\n      </collision>\n    </link>\n  </model>\n</sdf>\n'})}),"\n",(0,o.jsx)(e.h3,{id:"2d-lidar-configuration",children:"2D LiDAR Configuration"}),"\n",(0,o.jsx)(e.p,{children:"For simpler 2D navigation:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-xml",children:'<?xml version="1.0"?>\n<sdf version="1.7">\n  <model name="lidar_2d">\n    <link name="lidar_2d_link">\n      <pose>0 0 0.2 0 0 0</pose>\n      <inertial>\n        <mass>0.05</mass>\n        <inertia>\n          <ixx>0.00005</ixx>\n          <ixy>0</ixy>\n          <ixz>0</ixz>\n          <iyy>0.00005</iyy>\n          <iyz>0</iyz>\n          <izz>0.00005</izz>\n        </inertia>\n      </inertial>\n\n      <sensor name="lidar_2d" type="ray">\n        <pose>0 0 0 0 0 0</pose>\n        <ray>\n          <scan>\n            <horizontal>\n              <samples>360</samples>\n              <resolution>1</resolution>\n              <min_angle>-3.14159</min_angle>  \x3c!-- -\u03c0 --\x3e\n              <max_angle>3.14159</max_angle>   \x3c!-- \u03c0 --\x3e\n            </horizontal>\n          </scan>\n          <range>\n            <min>0.1</min>\n            <max>20.0</max>\n            <resolution>0.01</resolution>\n          </range>\n        </ray>\n        <plugin name="lidar_2d_controller" filename="libRayPlugin.so">\n          <always_on>true</always_on>\n          <update_rate>10</update_rate>\n          <topic_name>/scan</topic_name>\n        </plugin>\n      </sensor>\n\n      <visual name="lidar_2d_visual">\n        <geometry>\n          <box>\n            <size>0.04 0.04 0.04</size>\n          </box>\n        </geometry>\n        <material>\n          <ambient>0.8 0.2 0.2 1</ambient>\n          <diffuse>0.8 0.2 0.2 1</diffuse>\n        </material>\n      </visual>\n    </link>\n  </model>\n</sdf>\n'})}),"\n",(0,o.jsx)(e.h2,{id:"depth-camera-simulation",children:"Depth Camera Simulation"}),"\n",(0,o.jsx)(e.h3,{id:"depth-camera-principles",children:"Depth Camera Principles"}),"\n",(0,o.jsx)(e.p,{children:"Depth cameras provide both color (RGB) and depth information for each pixel, enabling 3D reconstruction and spatial understanding. The simulation typically combines a regular camera with a depth sensor."}),"\n",(0,o.jsx)(e.h3,{id:"gazebo-depth-camera-configuration",children:"Gazebo Depth Camera Configuration"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-xml",children:'<?xml version="1.0"?>\n<sdf version="1.7">\n  <model name="depth_camera">\n    <link name="camera_link">\n      <pose>0 0 0.15 0 0 0</pose>\n      <inertial>\n        <mass>0.1</mass>\n        <inertia>\n          <ixx>0.0001</ixx>\n          <ixy>0</ixy>\n          <ixz>0</ixz>\n          <iyy>0.0001</iyy>\n          <iyz>0</iyz>\n          <izz>0.0001</izz>\n        </inertia>\n      </inertial>\n\n      <sensor name="depth_camera" type="depth">\n        <pose>0 0 0 0 0 0</pose>\n        <camera>\n          <horizontal_fov>1.047</horizontal_fov>  \x3c!-- 60 degrees --\x3e\n          <image>\n            <width>640</width>\n            <height>480</height>\n            <format>R8G8B8</format>\n          </image>\n          <clip>\n            <near>0.1</near>\n            <far>10.0</far>\n          </clip>\n          <noise>\n            <type>gaussian</type>\n            <mean>0.0</mean>\n            <stddev>0.007</stddev>\n          </noise>\n        </camera>\n        <plugin name="camera_controller" filename="libDepthCameraPlugin.so">\n          <always_on>true</always_on>\n          <update_rate>30</update_rate>\n          <topic_name>/camera/rgb/image_raw</topic_name>\n          <depth_topic_name>/camera/depth/image_raw</depth_topic_name>\n          <point_cloud_topic_name>/camera/depth/points</point_cloud_topic_name>\n          <camera_info_topic_name>/camera/rgb/camera_info</camera_info_topic_name>\n        </plugin>\n      </sensor>\n\n      <visual name="camera_visual">\n        <geometry>\n          <box>\n            <size>0.05 0.05 0.03</size>\n          </box>\n        </geometry>\n        <material>\n          <ambient>0.2 0.2 0.8 1</ambient>\n          <diffuse>0.2 0.2 0.8 1</diffuse>\n        </material>\n      </visual>\n\n      <collision name="camera_collision">\n        <geometry>\n          <box>\n            <size>0.05 0.05 0.03</size>\n          </box>\n        </geometry>\n      </collision>\n    </link>\n  </model>\n</sdf>\n'})}),"\n",(0,o.jsx)(e.h2,{id:"imu-sensor-simulation",children:"IMU Sensor Simulation"}),"\n",(0,o.jsx)(e.h3,{id:"imu-principles",children:"IMU Principles"}),"\n",(0,o.jsx)(e.p,{children:"IMUs measure linear acceleration and angular velocity, providing crucial data for robot localization, navigation, and control. In simulation, IMU data includes realistic noise models."}),"\n",(0,o.jsx)(e.h3,{id:"gazebo-imu-configuration",children:"Gazebo IMU Configuration"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-xml",children:'<?xml version="1.0"?>\n<sdf version="1.7">\n  <model name="imu_sensor">\n    <link name="imu_link">\n      <pose>0 0 0.1 0 0 0</pose>\n      <inertial>\n        <mass>0.01</mass>\n        <inertia>\n          <ixx>0.000001</ixx>\n          <ixy>0</ixy>\n          <ixz>0</ixz>\n          <iyy>0.000001</iyy>\n          <iyz>0</iyz>\n          <izz>0.000001</izz>\n        </inertia>\n      </inertial>\n\n      <sensor name="imu_sensor" type="imu">\n        <pose>0 0 0 0 0 0</pose>\n        <imu>\n          <angular_velocity>\n            <x>\n              <noise type="gaussian">\n                <mean>0.0</mean>\n                <stddev>0.0017</stddev>  \x3c!-- ~0.1 deg/s stddev --\x3e\n              </noise>\n            </x>\n            <y>\n              <noise type="gaussian">\n                <mean>0.0</mean>\n                <stddev>0.0017</stddev>\n              </noise>\n            </y>\n            <z>\n              <noise type="gaussian">\n                <mean>0.0</mean>\n                <stddev>0.0017</stddev>\n              </noise>\n            </z>\n          </angular_velocity>\n          <linear_acceleration>\n            <x>\n              <noise type="gaussian">\n                <mean>0.0</mean>\n                <stddev>0.017</stddev>  \x3c!-- ~0.017 m/s\xb2 stddev --\x3e\n              </noise>\n            </x>\n            <y>\n              <noise type="gaussian">\n                <mean>0.0</mean>\n              <stddev>0.017</stddev>\n            </y>\n            <z>\n              <noise type="gaussian">\n                <mean>0.0</mean>\n                <stddev>0.017</stddev>\n              </noise>\n            </z>\n          </linear_acceleration>\n        </imu>\n        <plugin name="imu_controller" filename="libImuPlugin.so">\n          <always_on>true</always_on>\n          <update_rate>100</update_rate>\n          <topic_name>/imu/data</topic_name>\n        </plugin>\n      </sensor>\n\n      <visual name="imu_visual">\n        <geometry>\n          <box>\n            <size>0.01 0.01 0.01</size>\n          </box>\n        </geometry>\n        <material>\n          <ambient>0.8 0.8 0.2 1</ambient>\n          <diffuse>0.8 0.8 0.2 1</diffuse>\n        </material>\n      </visual>\n    </link>\n  </model>\n</sdf>\n'})}),"\n",(0,o.jsx)(e.h2,{id:"unity-sensor-visualization",children:"Unity Sensor Visualization"}),"\n",(0,o.jsx)(e.h3,{id:"point-cloud-visualization-in-unity",children:"Point Cloud Visualization in Unity"}),"\n",(0,o.jsx)(e.p,{children:"Creating visualizations for sensor data in Unity:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-csharp",children:'using UnityEngine;\nusing System.Collections.Generic;\n\npublic class PointCloudVisualizer : MonoBehaviour\n{\n    [Header("Visualization Settings")]\n    public GameObject pointPrefab;\n    public float pointSize = 0.01f;\n    public Color pointColor = Color.red;\n    public int maxPoints = 10000;\n\n    [Header("Data Input")]\n    public bool useLivePointCloud = false;\n    public float updateInterval = 0.1f;\n\n    private List<GameObject> pointObjects;\n    private List<Vector3> pointCloudData;\n    private float lastUpdateTime = 0f;\n\n    void Start()\n    {\n        pointObjects = new List<GameObject>();\n        pointCloudData = new List<Vector3>();\n\n        if (pointPrefab == null)\n        {\n            CreateDefaultPointPrefab();\n        }\n    }\n\n    void CreateDefaultPointPrefab()\n    {\n        // Create a simple sphere as point prefab\n        GameObject sphere = GameObject.CreatePrimitive(PrimitiveType.Sphere);\n        sphere.name = "PointCloudPoint";\n        sphere.GetComponent<Renderer>().material = new Material(Shader.Find("Universal Render Pipeline/Lit"));\n        sphere.GetComponent<Renderer>().material.color = pointColor;\n        sphere.transform.localScale = Vector3.one * pointSize;\n        sphere.SetActive(false);\n        pointPrefab = sphere;\n    }\n\n    void Update()\n    {\n        if (useLivePointCloud)\n        {\n            if (Time.time - lastUpdateTime > updateInterval)\n            {\n                UpdatePointCloudVisualization();\n                lastUpdateTime = Time.time;\n            }\n        }\n    }\n\n    public void UpdatePointCloud(List<Vector3> newPoints)\n    {\n        pointCloudData.Clear();\n        pointCloudData.AddRange(newPoints);\n\n        // Limit the number of points to avoid performance issues\n        if (pointCloudData.Count > maxPoints)\n        {\n            pointCloudData.RemoveRange(maxPoints, pointCloudData.Count - maxPoints);\n        }\n\n        UpdatePointCloudVisualization();\n    }\n\n    void UpdatePointCloudVisualization()\n    {\n        // Destroy old points\n        foreach (GameObject pointObj in pointObjects)\n        {\n            if (pointObj != null)\n            {\n                DestroyImmediate(pointObj);\n            }\n        }\n        pointObjects.Clear();\n\n        // Create new points\n        foreach (Vector3 point in pointCloudData)\n        {\n            GameObject pointObj = Instantiate(pointPrefab, point, Quaternion.identity, transform);\n            pointObj.SetActive(true);\n            pointObj.GetComponent<Renderer>().material.color = pointColor;\n            pointObj.transform.localScale = Vector3.one * pointSize;\n            pointObjects.Add(pointObj);\n        }\n    }\n\n    // Helper method to generate synthetic point cloud for demonstration\n    public void GenerateSamplePointCloud()\n    {\n        List<Vector3> points = new List<Vector3>();\n\n        // Generate a simple spherical point cloud\n        for (int i = 0; i < 1000; i++)\n        {\n            float theta = Random.Range(0f, 2f * Mathf.PI);\n            float phi = Random.Range(0f, Mathf.PI);\n            float radius = Random.Range(1f, 5f);\n\n            float x = radius * Mathf.Sin(phi) * Mathf.Cos(theta);\n            float y = radius * Mathf.Sin(phi) * Mathf.Sin(theta);\n            float z = radius * Mathf.Cos(phi);\n\n            points.Add(new Vector3(x, y, z));\n        }\n\n        UpdatePointCloud(points);\n    }\n}\n'})}),"\n",(0,o.jsx)(e.h3,{id:"sensor-data-processing-in-unity",children:"Sensor Data Processing in Unity"}),"\n",(0,o.jsx)(e.p,{children:"Processing and displaying sensor data:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-csharp",children:'using UnityEngine;\nusing System.Collections.Generic;\n\npublic class SensorDataProcessor : MonoBehaviour\n{\n    [Header("Sensor Data Sources")]\n    public PointCloudVisualizer pointCloudVisualizer;\n    public Camera depthCamera;\n    public TextMesh statusText;\n\n    [Header("Processing Settings")]\n    public bool enableRealTimeProcessing = true;\n    public float processingRate = 10f; // Hz\n\n    private float lastProcessingTime = 0f;\n    private Queue<SensorReading> sensorReadings;\n    private bool isProcessing = false;\n\n    [System.Serializable]\n    public class SensorReading\n    {\n        public Vector3 position;\n        public Vector3 rotation;\n        public Vector3 linearAcceleration;\n        public Vector3 angularVelocity;\n        public List<Vector3> pointCloud;\n        public float timestamp;\n\n        public SensorReading()\n        {\n            pointCloud = new List<Vector3>();\n            timestamp = Time.time;\n        }\n    }\n\n    void Start()\n    {\n        sensorReadings = new Queue<SensorReading>();\n        SetupSensors();\n    }\n\n    void SetupSensors()\n    {\n        if (depthCamera == null)\n        {\n            depthCamera = GetComponent<Camera>();\n        }\n\n        if (pointCloudVisualizer == null)\n        {\n            pointCloudVisualizer = FindObjectOfType<PointCloudVisualizer>();\n        }\n\n        if (statusText == null)\n        {\n            // Try to find a status text in child objects\n            statusText = GetComponentInChildren<TextMesh>();\n        }\n    }\n\n    void Update()\n    {\n        if (enableRealTimeProcessing)\n        {\n            if (Time.time - lastProcessingTime > 1f / processingRate)\n            {\n                ProcessSensorData();\n                lastProcessingTime = Time.time;\n            }\n        }\n\n        UpdateStatusDisplay();\n    }\n\n    public void ProcessSensorData()\n    {\n        isProcessing = true;\n\n        // Create a new sensor reading\n        SensorReading reading = new SensorReading();\n        reading.position = transform.position;\n        reading.rotation = transform.eulerAngles;\n        reading.linearAcceleration = CalculateLinearAcceleration();\n        reading.angularVelocity = CalculateAngularVelocity();\n\n        // Generate or receive point cloud data\n        reading.pointCloud = GeneratePointCloudFromDepthImage();\n\n        // Store the reading\n        sensorReadings.Enqueue(reading);\n\n        // Limit queue size to prevent memory issues\n        if (sensorReadings.Count > 100)\n        {\n            sensorReadings.Dequeue();\n        }\n\n        // Update visualization\n        if (pointCloudVisualizer != null)\n        {\n            pointCloudVisualizer.UpdatePointCloud(reading.pointCloud);\n        }\n\n        isProcessing = false;\n    }\n\n    Vector3 CalculateLinearAcceleration()\n    {\n        // Simplified calculation - in real implementation, this would come from IMU simulation\n        return new Vector3(\n            Mathf.Sin(Time.time) * 0.1f,\n            Mathf.Cos(Time.time) * 0.1f,\n            -9.81f + Mathf.Sin(Time.time * 2) * 0.05f\n        );\n    }\n\n    Vector3 CalculateAngularVelocity()\n    {\n        // Simplified calculation - in real implementation, this would come from IMU simulation\n        return new Vector3(\n            Mathf.Sin(Time.time * 0.5f) * 0.05f,\n            Mathf.Cos(Time.time * 0.3f) * 0.05f,\n            Mathf.Sin(Time.time * 0.7f) * 0.05f\n        );\n    }\n\n    List<Vector3> GeneratePointCloudFromDepthImage()\n    {\n        List<Vector3> points = new List<Vector3>();\n\n        // This is a simplified version - in a real implementation,\n        // this would process actual depth camera data\n        for (int i = 0; i < 100; i++)\n        {\n            // Generate random points in front of the camera\n            Vector3 point = transform.position + transform.forward * Random.Range(1f, 10f) +\n                           transform.right * Random.Range(-2f, 2f) +\n                           transform.up * Random.Range(-1f, 2f);\n\n            points.Add(point);\n        }\n\n        return points;\n    }\n\n    void UpdateStatusDisplay()\n    {\n        if (statusText != null)\n        {\n            statusText.text = $"Sensor Processing: {(isProcessing ? "ACTIVE" : "IDLE")}\\n" +\n                             $"Queue Size: {sensorReadings.Count}\\n" +\n                             $"Last Update: {lastProcessingTime:F2}s";\n        }\n    }\n\n    public SensorReading GetLatestReading()\n    {\n        if (sensorReadings.Count > 0)\n        {\n            return sensorReadings.Peek(); // Return the most recent reading\n        }\n        return null;\n    }\n\n    public List<SensorReading> GetHistoricalReadings(int count)\n    {\n        List<SensorReading> readings = new List<SensorReading>();\n        int itemsToTake = Mathf.Min(count, sensorReadings.Count);\n\n        // Take the most recent readings\n        var tempQueue = new Queue<SensorReading>(sensorReadings);\n        for (int i = 0; i < sensorReadings.Count - itemsToTake; i++)\n        {\n            tempQueue.Dequeue();\n        }\n\n        readings.AddRange(tempQueue);\n        return readings;\n    }\n}\n'})}),"\n",(0,o.jsx)(e.h2,{id:"sensor-integration-examples",children:"Sensor Integration Examples"}),"\n",(0,o.jsx)(e.h3,{id:"multi-sensor-fusion-world",children:"Multi-Sensor Fusion World"}),"\n",(0,o.jsx)(e.p,{children:"Combining multiple sensors in a single simulation:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-xml",children:'<?xml version="1.0"?>\n<sdf version="1.7">\n  <world name="multi_sensor_world">\n    <physics type="ode">\n      <max_step_size>0.001</max_step_size>\n      <real_time_factor>1</real_time_factor>\n      <real_time_update_rate>1000</real_time_update_rate>\n      <gravity>0 0 -9.8</gravity>\n    </physics>\n\n    \x3c!-- Ground plane --\x3e\n    <include>\n      <uri>model://ground_plane</uri>\n    </include>\n\n    \x3c!-- Sun light --\x3e\n    <include>\n      <uri>model://sun</uri>\n    </include>\n\n    \x3c!-- Robot with multiple sensors --\x3e\n    <model name="sensor_robot">\n      <pose>0 0 0.5 0 0 0</pose>\n      <link name="chassis">\n        <inertial>\n          <mass>10.0</mass>\n          <inertia>\n            <ixx>1.0</ixx>\n            <ixy>0</ixy>\n            <ixz>0</ixz>\n            <iyy>1.0</iyy>\n            <iyz>0</iyz>\n            <izz>1.0</izz>\n          </inertia>\n        </inertial>\n        <collision name="collision">\n          <geometry>\n            <box>\n              <size>0.5 0.3 0.2</size>\n            </box>\n          </geometry>\n        </collision>\n        <visual name="visual">\n          <geometry>\n            <box>\n              <size>0.5 0.3 0.2</size>\n            </box>\n          </geometry>\n          <material>\n            <ambient>0.8 0.8 0.8 1</ambient>\n            <diffuse>0.8 0.8 0.8 1</diffuse>\n          </material>\n        </visual>\n      </link>\n\n      \x3c!-- LiDAR sensor --\x3e\n      <model name="lidar_2d">\n        <pose>0.1 0 0.1 0 0 0</pose>\n        <link name="lidar_link">\n          <sensor name="lidar_2d" type="ray">\n            <pose>0 0 0 0 0 0</pose>\n            <ray>\n              <scan>\n                <horizontal>\n                  <samples>360</samples>\n                  <resolution>1</resolution>\n                  <min_angle>-3.14159</min_angle>\n                  <max_angle>3.14159</max_angle>\n                </horizontal>\n              </scan>\n              <range>\n                <min>0.1</min>\n                <max>20.0</max>\n                <resolution>0.01</resolution>\n              </range>\n            </ray>\n            <plugin name="lidar_2d_controller" filename="libRayPlugin.so">\n              <always_on>true</always_on>\n              <update_rate>10</update_rate>\n              <topic_name>/scan</topic_name>\n            </plugin>\n          </sensor>\n        </link>\n      </model>\n\n      \x3c!-- Depth camera --\x3e\n      <model name="depth_camera">\n        <pose>0.15 0 0.15 0 0 0</pose>\n        <link name="camera_link">\n          <sensor name="depth_camera" type="depth">\n            <camera>\n              <horizontal_fov>1.047</horizontal_fov>\n              <image>\n                <width>640</width>\n                <height>480</height>\n                <format>R8G8B8</format>\n              </image>\n              <clip>\n                <near>0.1</near>\n                <far>10.0</far>\n              </clip>\n            </camera>\n            <plugin name="camera_controller" filename="libDepthCameraPlugin.so">\n              <always_on>true</always_on>\n              <update_rate>30</update_rate>\n              <topic_name>/camera/rgb/image_raw</topic_name>\n              <depth_topic_name>/camera/depth/image_raw</depth_topic_name>\n            </plugin>\n          </sensor>\n        </link>\n      </model>\n\n      \x3c!-- IMU sensor --\x3e\n      <model name="imu_sensor">\n        <pose>0 0 0.05 0 0 0</pose>\n        <link name="imu_link">\n          <sensor name="imu_sensor" type="imu">\n            <imu>\n              <angular_velocity>\n                <x><noise type="gaussian"><stddev>0.0017</stddev></noise></x>\n                <y><noise type="gaussian"><stddev>0.0017</stddev></noise></y>\n                <z><noise type="gaussian"><stddev>0.0017</stddev></noise></z>\n              </angular_velocity>\n              <linear_acceleration>\n                <x><noise type="gaussian"><stddev>0.017</stddev></noise></x>\n                <y><noise type="gaussian"><stddev>0.017</stddev></noise></y>\n                <z><noise type="gaussian"><stddev>0.017</stddev></noise></z>\n              </linear_acceleration>\n            </imu>\n            <plugin name="imu_controller" filename="libImuPlugin.so">\n              <always_on>true</always_on>\n              <update_rate>100</update_rate>\n              <topic_name>/imu/data</topic_name>\n            </plugin>\n          </sensor>\n        </link>\n      </model>\n    </model>\n\n    \x3c!-- Obstacles for sensor testing --\x3e\n    <model name="obstacle1">\n      <pose>-2 1 0.5 0 0 0</pose>\n      <link name="link">\n        <collision name="collision">\n          <geometry>\n            <box>\n              <size>0.5 0.5 1.0</size>\n            </box>\n          </geometry>\n        </collision>\n        <visual name="visual">\n          <geometry>\n            <box>\n              <size>0.5 0.5 1.0</size>\n            </box>\n          </geometry>\n          <material>\n            <ambient>0.8 0.2 0.2 1</ambient>\n            <diffuse>0.8 0.2 0.2 1</diffuse>\n          </material>\n        </visual>\n        <inertial>\n          <mass>1.0</mass>\n          <inertia>\n            <ixx>0.083333</ixx>\n            <ixy>0</ixy>\n            <ixz>0</ixz>\n            <iyy>0.083333</iyy>\n            <iyz>0</iyz>\n            <izz>0.083333</izz>\n          </inertia>\n        </inertial>\n      </link>\n    </model>\n\n    <model name="obstacle2">\n      <pose>1 -1.5 0.3 0 0 0.5</pose>\n      <link name="link">\n        <collision name="collision">\n          <geometry>\n            <cylinder>\n              <radius>0.3</radius>\n              <length>0.6</length>\n            </cylinder>\n          </geometry>\n        </collision>\n        <visual name="visual">\n          <geometry>\n            <cylinder>\n              <radius>0.3</radius>\n              <length>0.6</length>\n            </cylinder>\n          </geometry>\n          <material>\n            <ambient>0.2 0.8 0.2 1</ambient>\n            <diffuse>0.2 0.8 0.2 1</diffuse>\n          </material>\n        </visual>\n        <inertial>\n          <mass>1.0</mass>\n          <inertia>\n            <ixx>0.0625</ixx>\n            <ixy>0</ixy>\n            <ixz>0</ixz>\n            <iyy>0.0625</iyy>\n            <iyz>0</iyz>\n            <izz>0.045</izz>\n          </inertia>\n        </inertial>\n      </link>\n    </model>\n  </world>\n</sdf>\n'})}),"\n",(0,o.jsx)(e.h2,{id:"exercises",children:"Exercises"}),"\n",(0,o.jsx)(e.h3,{id:"exercise-1-configure-a-lidar-sensor-and-visualize-its-point-cloud-data",children:"Exercise 1: Configure a LiDAR Sensor and Visualize Its Point Cloud Data"}),"\n",(0,o.jsx)(e.p,{children:"Configure a LiDAR sensor in Gazebo and implement visualization of its point cloud data in Unity:"}),"\n",(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsx)(e.li,{children:"Create a LiDAR sensor configuration with specific parameters (range, resolution, field of view)"}),"\n",(0,o.jsx)(e.li,{children:"Set up the sensor in a test world with obstacles"}),"\n",(0,o.jsx)(e.li,{children:"Implement a Unity script to visualize the resulting point cloud"}),"\n",(0,o.jsx)(e.li,{children:"Adjust sensor parameters and observe the changes in the point cloud"}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"exercise-2-simulate-depth-camera-data-for-a-simple-scene",children:"Exercise 2: Simulate Depth Camera Data for a Simple Scene"}),"\n",(0,o.jsx)(e.p,{children:"Create a depth camera simulation and process its data:"}),"\n",(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsx)(e.li,{children:"Configure a depth camera in Gazebo with realistic parameters"}),"\n",(0,o.jsx)(e.li,{children:"Set up a scene with various objects at different depths"}),"\n",(0,o.jsx)(e.li,{children:"Implement a Unity visualization for the depth data"}),"\n",(0,o.jsx)(e.li,{children:"Process the depth information to reconstruct 3D positions of objects"}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"summary",children:"Summary"}),"\n",(0,o.jsx)(e.p,{children:"In this chapter, you learned about sensor simulation for robotics applications:"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"How to configure LiDAR sensors for 3D mapping and navigation"}),"\n",(0,o.jsx)(e.li,{children:"Techniques for depth camera simulation and 3D vision"}),"\n",(0,o.jsx)(e.li,{children:"Implementation of IMU simulation with realistic noise models"}),"\n",(0,o.jsx)(e.li,{children:"Integration of sensor data visualization across Gazebo and Unity"}),"\n",(0,o.jsx)(e.li,{children:"Creating multi-sensor fusion scenarios for comprehensive perception"}),"\n"]}),"\n",(0,o.jsx)(e.p,{children:"These concepts enable the simulation of realistic sensor data for robotics development, allowing for thorough testing and validation of perception algorithms before deployment on physical robots."})]})}function m(n={}){const{wrapper:e}={...(0,t.R)(),...n.components};return e?(0,o.jsx)(e,{...n,children:(0,o.jsx)(c,{...n})}):c(n)}},8453(n,e,i){i.d(e,{R:()=>s,x:()=>r});var a=i(6540);const o={},t=a.createContext(o);function s(n){const e=a.useContext(t);return a.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function r(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(o):n.components||o:s(n.components),a.createElement(t.Provider,{value:e},n.children)}}}]);