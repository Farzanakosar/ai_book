"use strict";(globalThis.webpackChunkros2_book=globalThis.webpackChunkros2_book||[]).push([[87],{8453(n,e,i){i.d(e,{R:()=>r,x:()=>o});var t=i(6540);const s={},a=t.createContext(s);function r(n){const e=t.useContext(a);return t.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function o(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(s):n.components||s:r(n.components),t.createElement(a.Provider,{value:e},n.children)}},8535(n,e,i){i.r(e),i.d(e,{assets:()=>l,contentTitle:()=>o,default:()=>h,frontMatter:()=>r,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"isaac-sim/synthetic-data-generation","title":"Isaac Sim Synthetic Data Generation","description":"Overview","source":"@site/docs/isaac-sim/synthetic-data-generation.md","sourceDirName":"isaac-sim","slug":"/isaac-sim/synthetic-data-generation","permalink":"/docs/isaac-sim/synthetic-data-generation","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/isaac-sim/synthetic-data-generation.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Isaac Sim Workflows","permalink":"/docs/isaac-sim/workflows"},"next":{"title":"Isaac Sim Performance Optimization","permalink":"/docs/isaac-sim/performance"}}');var s=i(4848),a=i(8453);const r={},o="Isaac Sim Synthetic Data Generation",l={},c=[{value:"Overview",id:"overview",level:2},{value:"Key Benefits of Synthetic Data",id:"key-benefits-of-synthetic-data",level:2},{value:"Synthetic Data Pipeline",id:"synthetic-data-pipeline",level:2},{value:"Scene Creation for Data Generation",id:"scene-creation-for-data-generation",level:2},{value:"Environment Design",id:"environment-design",level:3},{value:"Asset Management",id:"asset-management",level:3},{value:"Sensor Configuration",id:"sensor-configuration",level:2},{value:"Camera Sensors",id:"camera-sensors",level:3},{value:"LiDAR Sensors",id:"lidar-sensors",level:3},{value:"Annotation Types",id:"annotation-types",level:2},{value:"2D Annotations",id:"2d-annotations",level:3},{value:"3D Annotations",id:"3d-annotations",level:3},{value:"Domain Randomization",id:"domain-randomization",level:2},{value:"Data Export Formats",id:"data-export-formats",level:2},{value:"COCO Format",id:"coco-format",level:3},{value:"KITTI Format",id:"kitti-format",level:3},{value:"Custom Formats",id:"custom-formats",level:3},{value:"Best Practices",id:"best-practices",level:2},{value:"Data Quality Assurance",id:"data-quality-assurance",level:3},{value:"Performance Optimization",id:"performance-optimization",level:3},{value:"Transfer Learning Considerations",id:"transfer-learning-considerations",level:3},{value:"Example Workflow: Object Detection Dataset",id:"example-workflow-object-detection-dataset",level:2},{value:"Troubleshooting",id:"troubleshooting",level:2},{value:"Annotation Quality Issues",id:"annotation-quality-issues",level:3},{value:"Performance Problems",id:"performance-problems",level:3},{value:"Next Steps",id:"next-steps",level:2}];function d(n){const e={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...n.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(e.header,{children:(0,s.jsx)(e.h1,{id:"isaac-sim-synthetic-data-generation",children:"Isaac Sim Synthetic Data Generation"})}),"\n",(0,s.jsx)(e.h2,{id:"overview",children:"Overview"}),"\n",(0,s.jsx)(e.p,{children:"Synthetic data generation is a core capability of Isaac Sim that enables the creation of large, diverse, and accurately labeled datasets for training AI models. Unlike real-world data collection, synthetic data generation provides unlimited data with perfect ground truth annotations, controlled environmental conditions, and diverse scenarios that would be difficult or impossible to capture in the real world."}),"\n",(0,s.jsx)(e.h2,{id:"key-benefits-of-synthetic-data",children:"Key Benefits of Synthetic Data"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Perfect Annotations"}),": Pixel-perfect segmentation, bounding boxes, and 3D annotations"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Unlimited Data"}),": Generate as much data as needed without physical constraints"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Controlled Environments"}),": Precise control over lighting, weather, and scene conditions"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Safety"}),": Generate dangerous scenarios without risk to people or equipment"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Cost-Effective"}),": No physical infrastructure or data collection teams required"]}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"synthetic-data-pipeline",children:"Synthetic Data Pipeline"}),"\n",(0,s.jsx)(e.p,{children:"The synthetic data generation process in Isaac Sim follows this general pipeline:"}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Scene Creation"}),": Build virtual environments with diverse objects, lighting, and physics"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Sensor Configuration"}),": Set up virtual sensors (cameras, LiDAR, IMU, etc.)"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Data Collection"}),": Run simulations to generate sensor data"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Annotation Generation"}),": Automatically create ground truth annotations"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Dataset Export"}),": Export data in standard formats for training"]}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"scene-creation-for-data-generation",children:"Scene Creation for Data Generation"}),"\n",(0,s.jsx)(e.h3,{id:"environment-design",children:"Environment Design"}),"\n",(0,s.jsx)(e.p,{children:"When creating scenes for synthetic data generation, consider:"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Diversity"}),": Include multiple lighting conditions, weather patterns, and environmental variations"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Realism"}),": Use physically accurate materials and lighting to match real-world conditions"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Variability"}),": Vary object positions, orientations, and configurations"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Annotation Readiness"}),": Ensure scenes are designed with annotation requirements in mind"]}),"\n"]}),"\n",(0,s.jsx)(e.h3,{id:"asset-management",children:"Asset Management"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Use high-quality 3D models with accurate physics properties"}),"\n",(0,s.jsx)(e.li,{children:"Include a variety of object textures, materials, and appearances"}),"\n",(0,s.jsx)(e.li,{children:"Implement domain randomization techniques to improve model generalization"}),"\n",(0,s.jsx)(e.li,{children:"Organize assets in a structured manner for easy scene composition"}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"sensor-configuration",children:"Sensor Configuration"}),"\n",(0,s.jsx)(e.h3,{id:"camera-sensors",children:"Camera Sensors"}),"\n",(0,s.jsx)(e.p,{children:"Configure camera sensors for different computer vision tasks:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:'# Example: Configuring a RGB camera for object detection\nfrom omni.isaac.core.utils.prims import get_prim_at_path\nfrom omni.isaac.sensor import Camera\n\n# Create a camera prim\ncamera = Camera(\n    prim_path="/World/Robot/Camera",\n    frequency=30,  # 30 Hz capture rate\n    resolution=(1920, 1080),  # Full HD resolution\n    position=np.array([0, 0, 1.0]),\n    orientation=usdrt.math.Quatf(0, 0, 0, 1)\n)\n\n# Enable RGB capture\ncamera.add_render_product("rgb", camera_resolution=(1920, 1080))\n'})}),"\n",(0,s.jsx)(e.h3,{id:"lidar-sensors",children:"LiDAR Sensors"}),"\n",(0,s.jsx)(e.p,{children:"For 3D object detection and mapping tasks:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:'# Example: Configuring a LiDAR sensor\nfrom omni.isaac.sensor import RotatingLidarPhysX\n\nlidar = RotatingLidarPhysX(\n    prim_path="/World/Robot/Lidar",\n    translation=np.array([0, 0, 1.5]),\n    config="Yosemite",\n    min_range=0.1,\n    max_range=25.0\n)\n'})}),"\n",(0,s.jsx)(e.h2,{id:"annotation-types",children:"Annotation Types"}),"\n",(0,s.jsx)(e.h3,{id:"2d-annotations",children:"2D Annotations"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Bounding Boxes"}),": 2D bounding boxes for object detection"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Semantic Segmentation"}),": Pixel-level class labels"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Instance Segmentation"}),": Pixel-level instance labels"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Keypoint Annotations"}),": 2D keypoint locations for pose estimation"]}),"\n"]}),"\n",(0,s.jsx)(e.h3,{id:"3d-annotations",children:"3D Annotations"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"3D Bounding Boxes"}),": 3D cuboids for objects in the scene"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Point Cloud Annotations"}),": Labeled point clouds from LiDAR"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"6D Pose"}),": Object position and orientation in 3D space"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"3D Keypoints"}),": 3D joint locations for articulated objects"]}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"domain-randomization",children:"Domain Randomization"}),"\n",(0,s.jsx)(e.p,{children:"Domain randomization is a technique to improve the transfer of models trained on synthetic data to real-world applications:"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Lighting Variation"}),": Randomize light positions, intensities, and colors"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Material Randomization"}),": Vary surface properties, textures, and appearances"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Camera Parameters"}),": Randomize camera intrinsics and extrinsics"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Environmental Conditions"}),": Vary weather, fog, and atmospheric effects"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Object Properties"}),": Randomize object textures, positions, and configurations"]}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"data-export-formats",children:"Data Export Formats"}),"\n",(0,s.jsx)(e.p,{children:"Isaac Sim supports export to various standard formats:"}),"\n",(0,s.jsx)(e.h3,{id:"coco-format",children:"COCO Format"}),"\n",(0,s.jsx)(e.p,{children:"For object detection and segmentation tasks:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-json",children:'{\n  "info": {...},\n  "licenses": [...],\n  "categories": [...],\n  "images": [...],\n  "annotations": [...]\n}\n'})}),"\n",(0,s.jsx)(e.h3,{id:"kitti-format",children:"KITTI Format"}),"\n",(0,s.jsx)(e.p,{children:"For 3D object detection:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{children:"Type,Truncated,Occluded,Alpha,Bbox_l,Bbox_t,Bbox_r,Bbox_b,Dim_h,Dim_w,Dim_l,Loc_x,Loc_y,Loc_z,Rot_y\nCar,0.00,0,0.82,415.9,153.8,561.5,248.2,1.67,1.87,3.72,2.74,1.56,16.1,1.65\n"})}),"\n",(0,s.jsx)(e.h3,{id:"custom-formats",children:"Custom Formats"}),"\n",(0,s.jsx)(e.p,{children:"For specialized applications, custom export formats can be implemented using Isaac Sim's Python API."}),"\n",(0,s.jsx)(e.h2,{id:"best-practices",children:"Best Practices"}),"\n",(0,s.jsx)(e.h3,{id:"data-quality-assurance",children:"Data Quality Assurance"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Validate annotations for accuracy and completeness"}),"\n",(0,s.jsx)(e.li,{children:"Check for occlusions and visibility issues"}),"\n",(0,s.jsx)(e.li,{children:"Verify sensor data quality and calibration"}),"\n",(0,s.jsx)(e.li,{children:"Implement automated quality checks in the pipeline"}),"\n"]}),"\n",(0,s.jsx)(e.h3,{id:"performance-optimization",children:"Performance Optimization"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Optimize scene complexity for desired frame rates"}),"\n",(0,s.jsx)(e.li,{children:"Use appropriate resolution settings for target applications"}),"\n",(0,s.jsx)(e.li,{children:"Implement efficient rendering techniques"}),"\n",(0,s.jsx)(e.li,{children:"Balance realism with computational requirements"}),"\n"]}),"\n",(0,s.jsx)(e.h3,{id:"transfer-learning-considerations",children:"Transfer Learning Considerations"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Include real-world data in training to bridge the sim-to-real gap"}),"\n",(0,s.jsx)(e.li,{children:"Use domain adaptation techniques"}),"\n",(0,s.jsx)(e.li,{children:"Validate model performance on real-world data"}),"\n",(0,s.jsx)(e.li,{children:"Implement gradual domain adaptation strategies"}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"example-workflow-object-detection-dataset",children:"Example Workflow: Object Detection Dataset"}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Create Scene"}),": Design a warehouse environment with various objects"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Configure Camera"}),": Set up RGB camera with appropriate parameters"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Randomize Environment"}),": Apply domain randomization techniques"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Run Simulation"}),": Generate data with different object configurations"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Export Annotations"}),": Export bounding box annotations in COCO format"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Validate Data"}),": Check data quality and annotation accuracy"]}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"troubleshooting",children:"Troubleshooting"}),"\n",(0,s.jsx)(e.h3,{id:"annotation-quality-issues",children:"Annotation Quality Issues"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Check sensor calibration and positioning"}),"\n",(0,s.jsx)(e.li,{children:"Verify object visibility and occlusion handling"}),"\n",(0,s.jsx)(e.li,{children:"Validate annotation pipeline settings"}),"\n",(0,s.jsx)(e.li,{children:"Adjust rendering quality settings if needed"}),"\n"]}),"\n",(0,s.jsx)(e.h3,{id:"performance-problems",children:"Performance Problems"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Reduce scene complexity or rendering resolution"}),"\n",(0,s.jsx)(e.li,{children:"Optimize asset complexity and polygon counts"}),"\n",(0,s.jsx)(e.li,{children:"Adjust simulation parameters for faster rendering"}),"\n",(0,s.jsx)(e.li,{children:"Use distributed rendering for large datasets"}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,s.jsx)(e.p,{children:"After implementing synthetic data generation:"}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.a,{href:"/docs/isaac-sim/workflows",children:"Isaac Sim Workflows"})," for best practices in data generation"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.a,{href:"../isaac-ros/introduction.md",children:"Isaac ROS Integration"})," to learn how to process synthetic data with Isaac ROS"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.a,{href:"/docs/isaac-sim/exercises",children:"Exercises"})," to practice synthetic data generation"]}),"\n"]})]})}function h(n={}){const{wrapper:e}={...(0,a.R)(),...n.components};return e?(0,s.jsx)(e,{...n,children:(0,s.jsx)(d,{...n})}):d(n)}}}]);