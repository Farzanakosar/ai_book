"use strict";(globalThis.webpackChunkros2_book=globalThis.webpackChunkros2_book||[]).push([[154],{7980(e,n,i){i.r(n),i.d(n,{assets:()=>a,contentTitle:()=>l,default:()=>p,frontMatter:()=>r,metadata:()=>s,toc:()=>d});const s=JSON.parse('{"id":"vla/prerequisites","title":"Voice-to-Action Prerequisites Guide","description":"Overview","source":"@site/docs/vla/prerequisites.md","sourceDirName":"vla","slug":"/vla/prerequisites","permalink":"/docs/vla/prerequisites","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/vla/prerequisites.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Introduction to Voice-to-Action Pipelines","permalink":"/docs/vla/introduction"},"next":{"title":"OpenAI Whisper Integration Guide","permalink":"/docs/vla/whisper-integration"}}');var t=i(4848),o=i(8453);const r={},l="Voice-to-Action Prerequisites Guide",a={},d=[{value:"Overview",id:"overview",level:2},{value:"System Requirements",id:"system-requirements",level:2},{value:"Hardware Requirements",id:"hardware-requirements",level:3},{value:"For Development and Testing",id:"for-development-and-testing",level:4},{value:"For Audio Capture",id:"for-audio-capture",level:4},{value:"Software Requirements",id:"software-requirements",level:3},{value:"Operating System",id:"operating-system",level:4},{value:"Core Software Dependencies",id:"core-software-dependencies",level:4},{value:"Python Packages",id:"python-packages",level:4},{value:"Development Environment Setup",id:"development-environment-setup",level:2},{value:"1. Python Virtual Environment",id:"1-python-virtual-environment",level:3},{value:"2. OpenAI API Configuration",id:"2-openai-api-configuration",level:3},{value:"3. Audio System Configuration",id:"3-audio-system-configuration",level:3},{value:"Installing PyAudio (may require additional steps)",id:"installing-pyaudio-may-require-additional-steps",level:4},{value:"Testing Audio Setup",id:"testing-audio-setup",level:4},{value:"Robotics Environment Setup",id:"robotics-environment-setup",level:2},{value:"ROS 2 Integration (Optional but Recommended)",id:"ros-2-integration-optional-but-recommended",level:3},{value:"1. Install ROS 2",id:"1-install-ros-2",level:4},{value:"2. Required ROS 2 Packages",id:"2-required-ros-2-packages",level:4},{value:"3. Python ROS 2 Client",id:"3-python-ros-2-client",level:4},{value:"Network and API Prerequisites",id:"network-and-api-prerequisites",level:2},{value:"1. OpenAI API Access",id:"1-openai-api-access",level:3},{value:"2. Rate Limits and Quotas",id:"2-rate-limits-and-quotas",level:3},{value:"3. Firewall and Proxy Settings",id:"3-firewall-and-proxy-settings",level:3},{value:"Testing Prerequisites",id:"testing-prerequisites",level:2},{value:"1. Basic API Test",id:"1-basic-api-test",level:3},{value:"2. Audio Test",id:"2-audio-test",level:3},{value:"Optional Enhancements",id:"optional-enhancements",level:2},{value:"1. Docker Setup (For Isolated Environment)",id:"1-docker-setup-for-isolated-environment",level:3},{value:"2. Development Tools",id:"2-development-tools",level:3},{value:"Troubleshooting Common Issues",id:"troubleshooting-common-issues",level:2},{value:"1. PyAudio Installation Issues",id:"1-pyaudio-installation-issues",level:3},{value:"2. Microphone Access Issues",id:"2-microphone-access-issues",level:3},{value:"3. API Connection Issues",id:"3-api-connection-issues",level:3},{value:"4. Audio Quality Issues",id:"4-audio-quality-issues",level:3},{value:"Verification Checklist",id:"verification-checklist",level:2},{value:"Next Steps",id:"next-steps",level:2}];function c(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",input:"input",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"voice-to-action-prerequisites-guide",children:"Voice-to-Action Prerequisites Guide"})}),"\n",(0,t.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,t.jsx)(n.p,{children:"This guide outlines the prerequisites needed to implement and run voice-to-action pipelines using OpenAI Whisper for robotics applications. Following these prerequisites ensures your system can properly process voice commands and map them to robot actions."}),"\n",(0,t.jsx)(n.h2,{id:"system-requirements",children:"System Requirements"}),"\n",(0,t.jsx)(n.h3,{id:"hardware-requirements",children:"Hardware Requirements"}),"\n",(0,t.jsx)(n.h4,{id:"for-development-and-testing",children:"For Development and Testing"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Processor"}),": 64-bit processor with 4+ cores (Intel i5 or AMD Ryzen 5 equivalent or better)"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"RAM"}),": 8GB+ (16GB recommended for simulation environments)"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Storage"}),": 10GB+ free disk space"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Network"}),": Stable internet connection (required for OpenAI API access)"]}),"\n"]}),"\n",(0,t.jsx)(n.h4,{id:"for-audio-capture",children:"For Audio Capture"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Microphone"}),": USB microphone or built-in laptop/desktop microphone"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Audio Quality"}),": Support for 16kHz sample rate, 16-bit depth preferred"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Noise Environment"}),": Quiet environment preferred for best results"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"software-requirements",children:"Software Requirements"}),"\n",(0,t.jsx)(n.h4,{id:"operating-system",children:"Operating System"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Windows"}),": Windows 10/11 (64-bit)"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"macOS"}),": macOS 10.14 or later"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Linux"}),": Ubuntu 18.04 or later, other distributions with Python 3.8+ support"]}),"\n"]}),"\n",(0,t.jsx)(n.h4,{id:"core-software-dependencies",children:"Core Software Dependencies"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Python"}),": Version 3.8 or higher"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"pip"}),": Python package installer (usually included with Python)"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Git"}),": Version control system"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"OpenAI API Key"}),": Required for Whisper access"]}),"\n"]}),"\n",(0,t.jsx)(n.h4,{id:"python-packages",children:"Python Packages"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"# Core packages\npip install openai\npip install python-dotenv  # For environment management\n\n# Audio processing\npip install pyaudio\npip install speechrecognition\npip install sounddevice\npip install numpy\n\n# For file handling\npip install pydub\npip install wave\n\n# Testing and utilities\npip install pytest\npip install requests\n"})}),"\n",(0,t.jsx)(n.h2,{id:"development-environment-setup",children:"Development Environment Setup"}),"\n",(0,t.jsx)(n.h3,{id:"1-python-virtual-environment",children:"1. Python Virtual Environment"}),"\n",(0,t.jsx)(n.p,{children:"Create and activate a virtual environment to isolate dependencies:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"# Create virtual environment\npython -m venv vla_env\n\n# Activate virtual environment\n# On Windows:\nvla_env\\Scripts\\activate\n# On macOS/Linux:\nsource vla_env/bin/activate\n\n# Upgrade pip\npip install --upgrade pip\n"})}),"\n",(0,t.jsx)(n.h3,{id:"2-openai-api-configuration",children:"2. OpenAI API Configuration"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Get OpenAI API Key"}),":"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Visit ",(0,t.jsx)(n.a,{href:"https://platform.openai.com/",children:"OpenAI Platform"})]}),"\n",(0,t.jsx)(n.li,{children:"Create an account or log in"}),"\n",(0,t.jsx)(n.li,{children:'Navigate to "API Keys" section'}),"\n",(0,t.jsx)(n.li,{children:"Create a new secret key"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Set Up Environment Variables"}),":"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:'# Create .env file in your project root\necho "OPENAI_API_KEY=your-api-key-here" > .env\n'})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Python Configuration"}),":"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'import openai\nimport os\nfrom dotenv import load_dotenv\n\n# Load environment variables\nload_dotenv()\n\n# Set OpenAI API key\nopenai.api_key = os.getenv("OPENAI_API_KEY")\n'})}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"3-audio-system-configuration",children:"3. Audio System Configuration"}),"\n",(0,t.jsx)(n.h4,{id:"installing-pyaudio-may-require-additional-steps",children:"Installing PyAudio (may require additional steps)"}),"\n",(0,t.jsx)(n.p,{children:"PyAudio can be tricky to install on some systems. Try these approaches:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"# Method 1: Direct pip install\npip install pyaudio\n\n# Method 2: If Method 1 fails, try pre-compiled wheels\npip install --only-binary=all pyaudio\n\n# Method 3: On Windows, you might need to download from:\n# https://www.lfd.uci.edu/~gohlke/pythonlibs/#pyaudio\n# Then install with: pip install path/to/downloaded/wheel\n"})}),"\n",(0,t.jsx)(n.h4,{id:"testing-audio-setup",children:"Testing Audio Setup"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'import pyaudio\nimport speech_recognition as sr\n\ndef test_audio_setup():\n    """Test if audio input/output is properly configured"""\n    print("Testing audio setup...")\n\n    # Test PyAudio\n    try:\n        p = pyaudio.PyAudio()\n        print(f"PyAudio: Available input devices: {p.get_device_count()}")\n        p.terminate()\n        print("\u2713 PyAudio is working correctly")\n    except Exception as e:\n        print(f"\u2717 PyAudio error: {e}")\n        return False\n\n    # Test SpeechRecognition\n    try:\n        r = sr.Recognizer()\n        with sr.Microphone() as source:\n            print("\u2713 SpeechRecognition can access microphone")\n    except Exception as e:\n        print(f"\u2717 SpeechRecognition error: {e}")\n        print("This might be due to missing audio drivers or PyAudio issues")\n        return False\n\n    return True\n\n# Run the test\nif test_audio_setup():\n    print("\\n\u2713 All audio prerequisites are met!")\nelse:\n    print("\\n\u2717 Some audio prerequisites need attention.")\n'})}),"\n",(0,t.jsx)(n.h2,{id:"robotics-environment-setup",children:"Robotics Environment Setup"}),"\n",(0,t.jsx)(n.h3,{id:"ros-2-integration-optional-but-recommended",children:"ROS 2 Integration (Optional but Recommended)"}),"\n",(0,t.jsx)(n.p,{children:"If integrating with ROS 2 for robot control:"}),"\n",(0,t.jsx)(n.h4,{id:"1-install-ros-2",children:"1. Install ROS 2"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Ubuntu"}),": Follow the official ROS 2 Humble Hawksbill installation guide"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Windows"}),": Use the Windows development guide"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"macOS"}),": Limited support, Ubuntu VM recommended"]}),"\n"]}),"\n",(0,t.jsx)(n.h4,{id:"2-required-ros-2-packages",children:"2. Required ROS 2 Packages"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"# Install ROS 2 desktop\nsudo apt install ros-humble-desktop\n\n# Install Python interfaces\nsudo apt install python3-rosdep python3-rosinstall python3-rosinstall-generator python3-wstool build-essential\n\n# Source ROS 2 environment\nsource /opt/ros/humble/setup.bash\n"})}),"\n",(0,t.jsx)(n.h4,{id:"3-python-ros-2-client",children:"3. Python ROS 2 Client"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"pip install ros2\npip install rclpy\n"})}),"\n",(0,t.jsx)(n.h2,{id:"network-and-api-prerequisites",children:"Network and API Prerequisites"}),"\n",(0,t.jsx)(n.h3,{id:"1-openai-api-access",children:"1. OpenAI API Access"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Verify your OpenAI account has sufficient credits"}),"\n",(0,t.jsx)(n.li,{children:"Check API usage limits and quotas"}),"\n",(0,t.jsx)(n.li,{children:"Ensure your network allows HTTPS connections to OpenAI endpoints"}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"2-rate-limits-and-quotas",children:"2. Rate Limits and Quotas"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Understand Whisper API rate limits (typically requests per minute)"}),"\n",(0,t.jsx)(n.li,{children:"Plan for cost management based on expected usage"}),"\n",(0,t.jsx)(n.li,{children:"Implement retry logic for rate limit handling"}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"3-firewall-and-proxy-settings",children:"3. Firewall and Proxy Settings"}),"\n",(0,t.jsx)(n.p,{children:"If behind a corporate firewall:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'import openai\n\n# Configure proxy if needed\nopenai.proxy = "http://your-proxy:port"\n'})}),"\n",(0,t.jsx)(n.h2,{id:"testing-prerequisites",children:"Testing Prerequisites"}),"\n",(0,t.jsx)(n.h3,{id:"1-basic-api-test",children:"1. Basic API Test"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'import openai\nimport os\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\ndef test_openai_connection():\n    """Test OpenAI API connection"""\n    try:\n        # Test with a simple completion\n        response = openai.ChatCompletion.create(\n            model="gpt-3.5-turbo",\n            messages=[{"role": "user", "content": "Hello"}],\n            max_tokens=5\n        )\n        print("\u2713 OpenAI API connection successful")\n        return True\n    except Exception as e:\n        print(f"\u2717 OpenAI API connection failed: {e}")\n        return False\n\n# Run the test\ntest_openai_connection()\n'})}),"\n",(0,t.jsx)(n.h3,{id:"2-audio-test",children:"2. Audio Test"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'import speech_recognition as sr\n\ndef test_audio_input():\n    """Test audio input capabilities"""\n    recognizer = sr.Recognizer()\n\n    try:\n        with sr.Microphone() as source:\n            print("Adjusting for ambient noise...")\n            recognizer.adjust_for_ambient_noise(source)\n            print("\u2713 Audio input test successful")\n            return True\n    except Exception as e:\n        print(f"\u2717 Audio input test failed: {e}")\n        print("This could be due to:")\n        print("- No microphone detected")\n        print("- Microphone permissions not granted")\n        print("- PyAudio not installed correctly")\n        return False\n\ntest_audio_input()\n'})}),"\n",(0,t.jsx)(n.h2,{id:"optional-enhancements",children:"Optional Enhancements"}),"\n",(0,t.jsx)(n.h3,{id:"1-docker-setup-for-isolated-environment",children:"1. Docker Setup (For Isolated Environment)"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-dockerfile",children:'FROM python:3.9-slim\n\n# Install system dependencies for audio\nRUN apt-get update && apt-get install -y \\\n    build-essential \\\n    portaudio19-dev \\\n    python3-dev \\\n    ffmpeg \\\n    && rm -rf /var/lib/apt/lists/*\n\n# Copy requirements and install Python packages\nCOPY requirements.txt .\nRUN pip install --no-cache-dir -r requirements.txt\n\nWORKDIR /app\nCOPY . .\n\nCMD ["python", "voice_robot.py"]\n'})}),"\n",(0,t.jsx)(n.h3,{id:"2-development-tools",children:"2. Development Tools"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"# Additional tools for development\npip install black          # Code formatting\npip install flake8         # Code linting\npip install pytest         # Testing framework\npip install pytest-cov     # Coverage reporting\n"})}),"\n",(0,t.jsx)(n.h2,{id:"troubleshooting-common-issues",children:"Troubleshooting Common Issues"}),"\n",(0,t.jsx)(n.h3,{id:"1-pyaudio-installation-issues",children:"1. PyAudio Installation Issues"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Problem"}),": ",(0,t.jsx)(n.code,{children:"pip install pyaudio"})," fails"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Solution"}),": Use pre-compiled wheels or install system packages:","\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"# Ubuntu/Debian\nsudo apt-get install python3-pyaudio\n\n# Or try conda\nconda install pyaudio\n"})}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"2-microphone-access-issues",children:"2. Microphone Access Issues"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Problem"}),': "No Microphone" or permission errors']}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Solution"}),": Check system audio settings and application permissions"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"3-api-connection-issues",children:"3. API Connection Issues"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Problem"}),': "Invalid API key" or connection errors']}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Solution"}),": Verify API key and network connectivity"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"4-audio-quality-issues",children:"4. Audio Quality Issues"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Problem"}),": Poor transcription quality"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Solution"}),": Use external microphone, reduce background noise, check audio format"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"verification-checklist",children:"Verification Checklist"}),"\n",(0,t.jsx)(n.p,{children:"Before proceeding with voice-to-action implementation, verify:"}),"\n",(0,t.jsxs)(n.ul,{className:"contains-task-list",children:["\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Python 3.8+ installed and accessible"]}),"\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","OpenAI API key configured and valid"]}),"\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Microphone accessible and functional"]}),"\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Required Python packages installed"]}),"\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Internet connection available for API calls"]}),"\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Audio system properly configured"]}),"\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","(Optional) ROS 2 environment set up if needed"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,t.jsx)(n.p,{children:"After verifying all prerequisites:"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["Proceed to the ",(0,t.jsx)(n.a,{href:"/docs/vla/whisper-integration",children:"OpenAI Whisper Integration Guide"})," to implement speech recognition"]}),"\n",(0,t.jsxs)(n.li,{children:["Move to ",(0,t.jsx)(n.a,{href:"/docs/vla/voice-command-mapping",children:"Voice Command Mapping"})," to connect voice commands to robot actions"]}),"\n",(0,t.jsxs)(n.li,{children:["Review ",(0,t.jsx)(n.a,{href:"/docs/vla/latency-accuracy",children:"Latency and Accuracy Considerations"})," for performance optimization"]}),"\n",(0,t.jsx)(n.li,{children:"Begin implementing the voice-to-action pipeline with the foundation established by these prerequisites"}),"\n"]})]})}function p(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(c,{...e})}):c(e)}},8453(e,n,i){i.d(n,{R:()=>r,x:()=>l});var s=i(6540);const t={},o=s.createContext(t);function r(e){const n=s.useContext(o);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:r(e.components),s.createElement(o.Provider,{value:n},e.children)}}}]);